#!/bin/bash -l
#$ -S /bin/bash
#$ -cwd
#$ -j y
#$ -m eas
#$ -N make_ucsc_references

# Build a set of reference FASTA files and indexes for a given UCSC genome build
# Adam Gower, based on script by Josh Campbell, originally derived from:
# https://github.com/infphilo/hisat2/tree/master/scripts/make_hg19.sh

# Parse command-line arguments
eval set -- "$(
  getopt --options=b:o: \
         --longoptions=build:,output-path: \
         --name "$0" -- "$@"
)"

while true
do
  case "$1" in
    -b|--build)
      ucsc_build="$2"
      shift 2 ;;
    -o|--output-path)
      output_path="$(readlink --canonicalize "$2")"
      shift 2 ;;
    --)
      shift
      break ;;
    *)
      echo "Internal error"
      exit 1 ;;
  esac
done

if [[ ${ucsc_build} == "" ]]
then
  echo    "Usage:"
  echo -n "  qsub make_ucsc_references.qsub [options] "
  echo    "-b|--build [UCSC genome build]"
  echo    "Options:"
  echo -n "  -b, --build          "
  echo    "UCSC genome build (e.g., hg38, mm10, etc.)"
  echo -n "  -o, --output-path    "
  echo -n "Path where output will be written "
  echo    "(will be created if it does not exist)"
  echo    "                       (Default: ./[UCSC genome build]/)"
else
  # If output path is not specified, a directory named with the UCSC genome
  # build will be created within the current working directory, and output will
  # be written there
  [[ "${output_path}" == "" ]] && output_path="$(pwd)/${ucsc_build}"

  # Load and list modules
  module load bwa
  module load picard
  module load samtools
  module list

  # Define URLs
  ucsc_base_url="hgdownload.cse.ucsc.edu/goldenPath"
  bigZips_url="ftp://${ucsc_base_url}/${ucsc_build}/bigZips"

  # Define filenames
  fa_gz_file="${ucsc_build}.fa.gz"
  bigZips_filenames=(${fa_gz_file} md5sum.txt)

  # Display the parsed arguments
  echo "UCSC genome build: ${ucsc_build}"
  echo "FASTA file and indexes will be written to: ${output_path}/"

  # Prepare for download
  cd $TMPDIR/ || exit
  echo "Retrieving files from ${bigZips_url}/ to: $TMPDIR"

  # Try retrieving each file from UCSC to scratch space;
  # if files could not be retrieved due to fatal error, terminate
  for filename in ${bigZips_filenames[@]}
  do
    wget ${bigZips_url}/${filename}
    if [[ ! -e ${filename} ]]
    then
      echo "File '${filename}' could not be retrieved; terminating."
      exit
    fi
  done

  # Verify MD5 checksum and print a message, terminating on invalid MD5 checksum
  if $(grep "${fa_gz_file}" md5sum.txt | md5sum --check --status)
  then
    echo "File '${fa_gz_file}' was retrieved correctly; proceeding."
  else
    echo "File '${fa_gz_file}' was not retrieved correctly; terminating."
    exit
  fi

  # Extract each entry in the fa.gz file to a separate .fa file
  echo "Splitting ${fa_gz_file} into individual .fa files."
  zcat ${fa_gz_file} | csplit --digits=4 - "%>%" "/>/" "{*}"
  # Rename the .fa files based on the header line
  for fa_file in xx*
  do
    mv -v ${fa_file} "$(head -n 1 ${fa_file} | cut -f2 -d'>').fa"
  done

  # Create the output path if it does not already exist
  [ ! -d "${output_path}" ] && mkdir --verbose -p "${output_path}"/ 
  # Ensure directory is not world-readable yet (to keep others out until ready)
  chmod 2700 "${output_path}"/

  # List "base" FASTA files (autosomes, X, Y, mtDNA)
  # Note: 'ls -v' is used to sort in "version" order instead of using default
  #       lexicographic sort (e.g., 1-22,X,Y instead of 1,10-19,2,20-22,3-9,X,Y)
  #       and chrM is listed separately so that it is placed after chrX and chrY
  base_files=(
    $(
      ls -v chr*.fa | grep -P "^chr([1-9][0-9]*|[XY])\.fa$"
      ls chrM.fa
    )
  )
  # Concatenate "base" FASTA files to create "base" reference genome
  mkdir --verbose --mode=2700 "${output_path}"/base/
  cat "${base_files[@]}" > "${output_path}"/base/${ucsc_build}.fa

  # Get a list of any FASTQ files corresponding to "random" contigs
  # Note: two listings are used to ensure that chr[XY]_*_random.fa appears
  #       before chrUn_*.fa
  # Note: '2>' throws away any output from stderr if the files are not found
  random_files=(
    $(
      ls -v chr*_*_random.fa 2> /dev/null
      ls -v chrUn_*.fa 2> /dev/null
    )
  )
  if [[ ${#random_files[@]} > 0 ]]
  then
    # Add unplaced FASTA files to create "base_random" reference genome
    mkdir --verbose --mode=2700 "${output_path}"/base_random/
    cp "${output_path}"/base/${ucsc_build}.fa \
       "${output_path}"/base_random/${ucsc_build}.fa
    cat "${random_files[@]}" >> "${output_path}"/base_random/${ucsc_build}.fa

    # Get a list of any alternative haplotype FASTA files
    # Note: hg19 includes filenames with format chr*_hap*.fa;
    #       hg38 includes filenames with format chr*_alt.fa
    # Note: '2>' throws away any output from stderr if the files are not found
    althap_files=($(ls -v chr*_alt.fa chr*_hap*.fa 2> /dev/null))
    if [[ ${#althap_files[@]} > 0 ]]
    then
      # Add alternative haplotype FASTA files to create
      # "base_random_althap" reference genome
      mkdir --verbose --mode=2700 "${output_path}"/base_random_althap/
      cp "${output_path}"/base_random/${ucsc_build}.fa \
         "${output_path}"/base_random_althap/${ucsc_build}.fa
      cat "${althap_files[@]}" >> \
        "${output_path}"/base_random_althap/${ucsc_build}.fa
    fi
  fi

  cd "${output_path}"/ || exit

  # Make indices and sequence dictionary for each concatenated FASTA file
  for type in *
  do
    bwa index -a bwtsw "${output_path}"/${type}/${ucsc_build}.fa
    samtools faidx "${output_path}"/${type}/${ucsc_build}.fa
    # Note: this step calls a wrapper script named 'picard' that calls Java
    #       with the 'picard.jar' file and 2GB maximum heap size
    picard CreateSequenceDictionary \
       REFERENCE="${output_path}"/${type}/${ucsc_build}.fa \
       OUTPUT="${output_path}"/${type}/${ucsc_build}.dict
  done
  # Make all output files and directories world-readable and read-only
  chmod -Rc ugo-w,ugo+rX .

  # Clean up scratch space
  rm -rf ${TMPDIR:?}/*
fi
